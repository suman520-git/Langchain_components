{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8b9c77",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638e6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733b111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001D4FE50DDB0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D4FE570F70> root_client=<openai.OpenAI object at 0x000001D4FE50C820> root_async_client=<openai.AsyncOpenAI object at 0x000001D4FE570E20> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9b2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061d6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence techniques that are designed to create data or content. It leverages models, often involving neural networks, that can generate new data instances similar to the data on which they were trained. Generative AI is commonly used to produce a wide variety of outputs, including but not limited to:\\n\\n1. **Text Generation**: Crafting articles, stories, or dialogues based on prompts. Examples include models like OpenAI's GPT-3, which can write coherent and contextually relevant text.\\n\\n2. **Image Creation**: Producing new images or artworks. Generative Adversarial Networks (GANs) have been popular for this purpose, where two neural networks work in opposition to create realistic images.\\n\\n3. **Music and Audio**: Composing original pieces of music or generating sound effects.\\n\\n4. **Code and Algorithms**: Assisting in the creation of software code, offering suggestions, and even fixing bugs in code.\\n\\n5. **Design and Patterns**: Generating design elements or architectural patterns.\\n\\nGenerative AI can be particularly powerful and versatile, offering creative assistance, enhancing productivity, and driving innovation across various fields. However, it also raises ethical considerations, such as content ownership, potential biases in generated content, and the implications of creating deepfakes or misinformation.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 265, 'prompt_tokens': 13, 'total_tokens': 278, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BpXR9USbciARQervvkTEw35s83ua4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--12d2abf6-e0c5-4b31-a21f-28183464cec7-0' usage_metadata={'input_tokens': 13, 'output_tokens': 265, 'total_tokens': 278, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f46c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1a2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a toolset designed for the development, testing, and monitoring of applications that utilize language models. It supports the creation of both straightforward applications, such as summarization tools, and more complex applications, like personal assistants that require multiple steps and integrations. With Langsmith, developers can gain better control over the outputs of language models by utilizing features that allow for in-depth testing and debugging. The tool provides insights into how these models work, enabling developers to fine-tune prompts and workflows for optimal performance. Additionally, Langsmith allows for the collection of telemetry data to help improve system reliability and user experience over time. It is part of the broader ecosystem of tools that support the development of AI-driven applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 142, 'prompt_tokens': 33, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BpXRQNTdwC6BrGEypnlx6xZjVsUxT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8d81cbaf-8677-4bd4-bbcb-a6764ba85269-0' usage_metadata={'input_tokens': 33, 'output_tokens': 142, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224ca240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d035540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain that helps developers build and evaluate applications powered by large language models (LLMs). It provides robust monitoring, testing, and tracing capabilities, which are essential for refining and improving the performance of applications utilizing LLMs. With Langsmith, developers can gain valuable insights into how their language model applications perform and make incremental improvements by understanding various aspects such as response quality, efficiency, and error handling. The tool is particularly useful for those who are creating complex applications that depend heavily on natural language processing and require ongoing optimization and analysis.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf89a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db14b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13969b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
